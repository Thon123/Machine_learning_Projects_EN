{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with MLlib and PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- audio\n",
    "- text editing & translation \n",
    "- text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning computer to read using Count Vectors! Transforming words to numbers. Basic data processing steps are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove stop words, punctuation, white space, special characters (in some cases we want use special characters in a different way)\n",
    "- simplify text using stemming (deleting -ing and so on)\n",
    "- extract features -> count vectors\n",
    "- train and test\n",
    "- apply the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Feature Transformers</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loss](nlp1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Noise cleaning***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It depends, for example hastags. In some special character you will want to leave them alone. But spaces and so on, are just a redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***RegexTokenizer***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just splitting our text to cells, each words has to have its own column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Stop Words***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a list of words I wanna exclude from my analysis. PySpark offer default list of stopwords for some languages (not Czech :()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***n-gram***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optional splitting of my sentences, it is better to use algorithm with more n-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Feature Extractors</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We have more methods for extracting features from our text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Count Vectorizer***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple and easy, also very effective. Only lists of words and assigning numbers from 1 to 0 - if the sentence containts the word or not. Main disadvantage of Count Vectorizer is that, it's not possible to map order of word in sentences. Algorithm just know that some sentence only contains some word nothing else. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TF-IDF***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loss](nlp2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea is simple: it measures the importance of the word by comparing its frequency in larger datasets. For example AND is probably not so important for meaning of sentence as SUN for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Word2Vec***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is trying to understand the contextual differences between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Feature Hashing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works by creating an indexed vocabulary, where user can specify how many values they want to store in their vocab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "1. Quality check \n",
    "2. Clean up the data - special characters, punctuation and so on\n",
    "3. Tokenize \n",
    "4. Stopwords\n",
    "5. Zero index for label column\n",
    "5. Create ML Pipeline\n",
    "6. Vectorize\n",
    "7. Train, evaluate and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Session, dependencies and data info</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.36:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x28c86bf27c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import * #CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import * #col, udf,regexp_replace,isnull\n",
    "from pyspark.sql.types import * #StringType,IntegerType\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# For pipeline development\n",
    "from pyspark.ml import Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kickstarter Dataset\n",
    "\n",
    "##### What is Kickstarter?\n",
    "\"Kickstarter is an American public-benefit corporation based in Brooklyn, New York, that maintains a global crowdfunding platform, focused on creativity and merchandising. The company's stated mission is to \"help bring creative projects to life\". Kickstarter, has reportedly received more than $1.9 billion in pledges from 9.4 million backers to fund 257,000 creative projects, such as films, music, stage shows, comics, journalism, video games, technology and food-related projects.\n",
    "\n",
    "People who back Kickstarter projects are offered tangible rewards or experiences in exchange for their pledges. This model traces its roots to subscription model of arts patronage, where artists would go directly to their audiences to fund their work\" ~ Wikipedia\n",
    "\n",
    "So, what if you can predict if a project will be or not to be able to get the money from their backers?\n",
    "\n",
    "#### Content\n",
    "\n",
    "The datastet contains the blurbs or short description of 215,513 projects runned along 2017, all written in english and all labeled with \"successful\" or \"failed\", if they get the money or not, respectively. From those texts you can train linguistics models for description, and even embeddings relative to the case.\n",
    "\n",
    "**Source:** https://www.kaggle.com/oscarvilla/kickstarter-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading our csv\n",
    "path =\"Datasets/\"\n",
    "df = spark.read.csv(path+'kickstarter.csv',inferSchema=True,header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using their own character, users go on educati...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MicroFly is a quadcopter packed with WiFi, 6 s...</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A small indie press, run as a collective for a...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Zylor is a new baby cosplayer! Back this kicks...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hatoful Boyfriend meet Skeletons! A comedy Dat...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state\n",
       "0   1  Using their own character, users go on educati...      failed\n",
       "1   2  MicroFly is a quadcopter packed with WiFi, 6 s...  successful\n",
       "2   3  A small indie press, run as a collective for a...      failed\n",
       "3   4  Zylor is a new baby cosplayer! Back this kicks...      failed\n",
       "4   5  Hatoful Boyfriend meet Skeletons! A comedy Dat...      failed"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|_c0|blurb                                                                                                                              |state     |\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|1  |Using their own character, users go on educational quests around a virtual world leveling up subject-oriented skills (ie Physics). |failed    |\n",
      "|2  |MicroFly is a quadcopter packed with WiFi, 6 sensors, and 3 processors for ultimate stability -- and fits in the palm of your hand.|successful|\n",
      "|3  |A small indie press, run as a collective for authors who want to self-publish, and a sexy, smart , hilarious novel!                |failed    |\n",
      "|4  |Zylor is a new baby cosplayer! Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world!    |failed    |\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(4,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I can spot some special characters, white spaces and so on.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- blurb: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No problem with datatypes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Data cleaning</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223627"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() #calculating number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No lets calculate Null values - I use function from previous parts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------------------+\n",
      "|Column_Name|Null_Values_Count|Null_Value_Percent|\n",
      "+-----------+-----------------+------------------+\n",
      "|      blurb|             1488|0.6653937136392296|\n",
      "|      state|            13157| 5.883457722010312|\n",
      "+-----------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def null_value_calc(df):\n",
    "    null_columns_counts = []\n",
    "    numRows = df.count()\n",
    "    for k in df.columns:\n",
    "        nullRows = df.where(col(k).isNull()).count()\n",
    "        if(nullRows > 0):\n",
    "            temp = k,nullRows,(nullRows/numRows)*100\n",
    "            null_columns_counts.append(temp)\n",
    "    return(null_columns_counts)\n",
    "\n",
    "null_columns_calc_list = null_value_calc(df)\n",
    "spark.createDataFrame(null_columns_calc_list, ['Column_Name', 'Null_Values_Count','Null_Value_Percent']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our state column has 5,88% of null values and blub has 0.66% of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210470"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.na.drop().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If i dropp all rows with Nan values I will drop from 223K rows to 210K, I will accept that.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210470"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna() #Dropping\n",
    "df.count() #Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now I will check state column, our label column. It has to be cleaned also..*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               state| count|\n",
      "+--------------------+------+\n",
      "|          successful|103582|\n",
      "|              failed|102000|\n",
      "| and get some col...|     8|\n",
      "|          \",\"failed\"|     6|\n",
      "|     their childhood|     6|\n",
      "|                love|     6|\n",
      "| about a lonely f...|     5|\n",
      "|             romance|     4|\n",
      "|              poetry|     4|\n",
      "|            mastered|     4|\n",
      "| She Wrote\"\" but ...|     3|\n",
      "|              2015.\"|     3|\n",
      "|                loss|     3|\n",
      "|                NY.\"|     3|\n",
      "|               2014\"|     3|\n",
      "|            betrayal|     3|\n",
      "|               faith|     3|\n",
      "| solid surface on...|     3|\n",
      "|               music|     3|\n",
      "|                  CD|     3|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"state\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I have 205K of valid label values, and 5k of unvalid. I will drop all rows which does not contain successful or failed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(\"state IN('successful','failed')\") #filtering and assigning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|     state| count|\n",
      "+----------+------+\n",
      "|successful|103582|\n",
      "|    failed|102000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"state\").count().orderBy(col(\"count\").desc()).show() #just checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now I will proceed with special characters removing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character, users go on educational quests around a virtual world leveling up subject-oriented skills  ie Physics . |\n",
      "|MicroFly is a quadcopter packed with WiFi, 6 sensors, and 3 processors for ultimate stability -- and fits in the palm of your hand.|\n",
      "|A small indie press, run as a collective for authors who want to self-publish, and a sexy, smart , hilarious novel!                |\n",
      "|Zylor is a new baby cosplayer! Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world!    |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"blurb\").show(4,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Deleting / ) (.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"blurb\", translate(col(\"blurb\"), \"/\", \" \"))\\\n",
    ".withColumn(\"blurb\", translate(col(\"blurb\"), \")\", \" \"))\\\n",
    ".withColumn(\"blurb\", translate(col(\"blurb\"), \"(\", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Deleting other specical characters using Regexp.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                         |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie Physics |\n",
      "|MicroFly is a quadcopter packed with WiFi sensors and processors for ultimate stability and fits in the palm of your hand     |\n",
      "|A small indie press run as a collective for authors who want to selfpublish and a sexy smart hilarious novel                  |\n",
      "|Zylor is a new baby cosplayer Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"blurb\",regexp_replace(col('blurb'), '[^A-Za-z ]+', ''))\n",
    "df = df.withColumn(\"blurb\",regexp_replace(col('blurb'), ' +', ' '))\n",
    "df.select(\"blurb\").show(4,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now case sensitivity, we will change everything to lower.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                         |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |\n",
      "|microfly is a quadcopter packed with wifi sensors and processors for ultimate stability and fits in the palm of your hand     |\n",
      "|a small indie press run as a collective for authors who want to selfpublish and a sexy smart hilarious novel                  |\n",
      "|zylor is a new baby cosplayer back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"blurb\",lower(col('blurb')))\n",
    "df.select(\"blurb\").show(4,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Tokenizing, StopWords and Zero Index</b></div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------------------------------------------------------------------------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_c0|blurb                                                                                                                         |state     |words                                                                                                                                               |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |failed    |[using, their, own, character, users, go, on, educational, quests, around, a, virtual, world, leveling, up, subjectoriented, skills, ie, physics]   |\n",
      "|2  |microfly is a quadcopter packed with wifi sensors and processors for ultimate stability and fits in the palm of your hand     |successful|[microfly, is, a, quadcopter, packed, with, wifi, sensors, and, processors, for, ultimate, stability, and, fits, in, the, palm, of, your, hand]     |\n",
      "|3  |a small indie press run as a collective for authors who want to selfpublish and a sexy smart hilarious novel                  |failed    |[a, small, indie, press, run, as, a, collective, for, authors, who, want, to, selfpublish, and, a, sexy, smart, hilarious, novel]                   |\n",
      "|4  |zylor is a new baby cosplayer back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world |failed    |[zylor, is, a, new, baby, cosplayer, back, this, kickstarter, to, help, fund, new, cosplay, photoshoots, to, share, his, cuteness, with, the, world]|\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- blurb: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"blurb\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "#our tokenizer use blurb column, new column is words, patter is just basic param W - looking for word..\n",
    "raw_words = regex_tokenizer.transform(df) #transforming our data\n",
    "raw_words.show(4,False)\n",
    "raw_words.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Every row  token in this case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|-- words: array (nullable = true)\n",
    "#  |    |-- element: string (containsNull = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StopWords**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanna delete most common words via StopWords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\") #seting up my remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = remover.getStopWords() #filling remover with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:5] #first 5 words for deleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords) #purely out of curiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = remover.transform(raw_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "\n",
       "                                            filtered  \n",
       "0  [using, character, users, go, educational, que...  \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...  \n",
       "2  [small, indie, press, run, collective, authors...  \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.limit(4).toPandas() #look at our changes - blurb - words - filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "\n",
       "                                            filtered  label  \n",
       "0  [using, character, users, go, educational, que...    1.0  \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...    0.0  \n",
       "2  [small, indie, press, run, collective, authors...    1.0  \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...    1.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"state\", outputCol=\"label\") #changing our label column\n",
    "feature_data = indexer.fit(words_df).transform(words_df) #indexer just replace failed and successful to numbers\n",
    "\n",
    "feature_data.limit(4).toPandas() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now i can see that failed is evaluated as 1 and 0 is successful. Now all three procedures in Pipeline.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb       state  \\\n",
       "0   1  using their own character users go on educatio...      failed   \n",
       "1   2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2   3  a small indie press run as a collective for au...      failed   \n",
       "3   4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "1  [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2  [a, small, indie, press, run, as, a, collectiv...   \n",
       "3  [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "\n",
       "                                            filtered  label  \n",
       "0  [using, character, users, go, educational, que...    1.0  \n",
       "1  [microfly, quadcopter, packed, wifi, sensors, ...    0.0  \n",
       "2  [small, indie, press, run, collective, authors...    1.0  \n",
       "3  [zylor, new, baby, cosplayer, back, kickstarte...    1.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"blurb\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=regex_tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "#remover is calling regexttokenizer outpit to be his input..\n",
    "indexer = StringIndexer(inputCol=\"state\", outputCol=\"label\")\n",
    "\n",
    "pipeline = Pipeline(stages=[regex_tokenizer,remover,indexer]) #creating a pipeline\n",
    "data_prep_pl = pipeline.fit(df) #I am fitting my pipline\n",
    "feature_data = data_prep_pl.transform(df) #transforming\n",
    "feature_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>BeAware:</b> main purspose of using pipelines is speed and readibility</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors, tests and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Vectors</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hashing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawfeatures\", numFeatures=20)\n",
    "HTFfeaturizedData = hashingTF.transform(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>rawfeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb   state  \\\n",
       "0   1  using their own character users go on educatio...  failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [using, character, users, go, educational, que...    1.0   \n",
       "\n",
       "                                         rawfeatures  \n",
       "0  (3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTFfeaturizedData.limit(1).toPandas() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I can see that Hashing is just using integer number, simple vocab indexer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawfeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData = idfModel.transform(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData.name = 'TFIDFfeaturizedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>rawfeatures</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, ...</td>\n",
       "      <td>(2.252148827177929, 0.0, 0.8915391572399594, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb   state  \\\n",
       "0   1  using their own character users go on educatio...  failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [using, character, users, go, educational, que...    1.0   \n",
       "\n",
       "                                         rawfeatures  \\\n",
       "0  (3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, ...   \n",
       "\n",
       "                                            features  \n",
       "0  (2.252148827177929, 0.0, 0.8915391572399594, 0...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDFfeaturizedData.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTFfeaturizedData = HTFfeaturizedData.withColumnRenamed(\"rawfeatures\",\"features\")\n",
    "HTFfeaturizedData.name = 'HTFfeaturizedData' #We will use later for printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered\", outputCol=\"features\")\n",
    "model = word2Vec.fit(feature_data)\n",
    "W2VfeaturizedData = model.transform(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.21108862035907805, -0.06200759852072224, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb   state  \\\n",
       "0   1  using their own character users go on educatio...  failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [using, character, users, go, educational, que...    1.0   \n",
       "\n",
       "                                            features  \n",
       "0  [-0.21108862035907805, -0.06200759852072224, 0...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2VfeaturizedData.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I have negative values, lets repare that, using MinMaxScaler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>scaledFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.21108862035907805, -0.06200759852072224, 0...</td>\n",
       "      <td>[0.4320722381613357, 0.5392954626524695, 0.608...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                              blurb   state  \\\n",
       "0   1  using their own character users go on educatio...  failed   \n",
       "\n",
       "                                               words  \\\n",
       "0  [using, their, own, character, users, go, on, ...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [using, character, users, go, educational, que...    1.0   \n",
       "\n",
       "                                            features  \\\n",
       "0  [-0.21108862035907805, -0.06200759852072224, 0...   \n",
       "\n",
       "                                      scaledFeatures  \n",
       "0  [0.4320722381613357, 0.5392954626524695, 0.608...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(W2VfeaturizedData)\n",
    "scaled_data = scalerModel.transform(W2VfeaturizedData)\n",
    "scaled_data.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2VfeaturizedData = scaled_data.select('state','blurb','label','scaledFeatures')\n",
    "W2VfeaturizedData = W2VfeaturizedData.withColumnRenamed('scaledFeatures','features')\n",
    "\n",
    "W2VfeaturizedData.name = 'W2VfeaturizedData'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vector (count vectorizer and hashingTF are basically the same thing)\n",
    "# cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "# model = cv.fit(feature_data)\n",
    "# countVectorizer_features = model.transform(feature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it we have three different datatypes so we can compare different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Testing</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it is just Copy and Paste of previous testing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassTrainEval(classifier,features,classes,train,test):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "    \n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
    "        \n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # instantiate the base classifier.\n",
    "            lr = LogisticRegression()\n",
    "            # instantiate the One Vs Rest Classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "#             fitModel = OVRclassifier.fit(train)\n",
    "            # Add parameters of your choice here:\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "                .build()\n",
    "            #Cross Validator requires the following parameters:\n",
    "            crossval = CrossValidator(estimator=OVRclassifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 is best practice\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # specify layers for the neural network:\n",
    "            # input layer of size features, two intermediate of features+1 and same size as features\n",
    "            # and output of size number of classes\n",
    "            # Note: crossvalidator cannot be used here\n",
    "            features_count = len(features[0][0])\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: # These classifiers currently only accept binary classification\n",
    "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "            return\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "  \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LogisticRegression\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"NaiveBayes\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LinearSVC\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .build())\n",
    "            \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .build())\n",
    "            \n",
    "            #Cross Validator requires all of the following parameters:\n",
    "            crossval = CrossValidator(estimator=classifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 + is best practice\n",
    "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
    "    \n",
    "    # Print feature selection metrics\n",
    "    if fitModel is not None:\n",
    "        \n",
    "        if Mtype in(\"OneVsRest\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            # Extract list of binary models\n",
    "            models = BestModel.models\n",
    "            for model in models:\n",
    "                print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            print(\"\")\n",
    "            print('\\033[1m' + Mtype,\" Weights\"+ '\\033[0m')\n",
    "            print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "            print(\"\")\n",
    "\n",
    "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\n",
    "            # FEATURE IMPORTANCES\n",
    "            # Estimate of the importance of each feature.\n",
    "            # Each features importance is the average of its importance across all trees \n",
    "            # in the ensemble The importance vector is normalized to sum to 1. \n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Feature Importances\"+ '\\033[0m')\n",
    "            print(\"(Scores add up to 1)\")\n",
    "            print(\"Lowest score is the least important\")\n",
    "            print(\" \")\n",
    "            print(BestModel.featureImportances)\n",
    "            \n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                global DT_featureimportances\n",
    "                DT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global DT_BestModel\n",
    "                DT_BestModel = BestModel\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                global GBT_featureimportances\n",
    "                GBT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global GBT_BestModel\n",
    "                GBT_BestModel = BestModel\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                global RF_featureimportances\n",
    "                RF_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global RF_BestModel\n",
    "                RF_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LogisticRegression\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficient Matrix\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "            print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "            global LR_coefficients\n",
    "            LR_coefficients = BestModel.coefficientMatrix.toArray()\n",
    "            global LR_BestModel\n",
    "            LR_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LinearSVC\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficients\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "            global LSVC_coefficients\n",
    "            LSVC_coefficients = BestModel.coefficients.toArray()\n",
    "            global LSVC_BestModel\n",
    "            LSVC_BestModel = BestModel\n",
    "        \n",
    "   \n",
    "    # Set the column names to match the external results dataframe that we will join with later:\n",
    "    columns = ['Classifier', 'Result']\n",
    "    \n",
    "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
    "        Mtype = [Mtype] # make this a list\n",
    "        score = [\"N/A\"]\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    else:\n",
    "        predictions = fitModel.transform(test)\n",
    "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
    "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "        Mtype = [Mtype] # make this a string\n",
    "        score = [str(accuracy)] #make this a string and convert to a list\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "        \n",
    "    return result\n",
    "    #Also returns the fit model important scores or p values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classifiers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "                LogisticRegression()\n",
    "                ,OneVsRest()\n",
    "               ,LinearSVC()\n",
    "               ,NaiveBayes()\n",
    "               ,RandomForestClassifier()\n",
    "               ,GBTClassifier()\n",
    "               ,DecisionTreeClassifier()\n",
    "               ,MultilayerPerceptronClassifier()\n",
    "              ] \n",
    "\n",
    "featureDF_list = [HTFfeaturizedData,TFIDFfeaturizedData,W2VfeaturizedData]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Testing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHTFfeaturizedData  Results:\u001b[0m\n",
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.0306558 ,  0.00836233, -0.08115937,  0.00139624, -0.02171133,\n",
      "              -0.11053216, -0.06898924, -0.03201325, -0.02120355, -0.04344437,\n",
      "               0.05290475, -0.02900662,  0.00445361, -0.0025032 , -0.02611517,\n",
      "              -0.0330324 ,  0.01511948, -0.02616886, -0.0829429 , -0.03019649]])\n",
      "Intercept: [0.3028264529031553]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -0.2853059211210915 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.029062550035724388,-0.008573954952669945,0.07756454991579075,-0.001858825564054125,0.02049059396015637,0.10594430189080854,0.06590565945980054,0.03048662301298438,0.020037390180429354,0.04122018280382074,-0.05125338132578102,0.02735803301400113,-0.004876058918745418,0.001901812512298275,0.024610619660272757,0.031235391956357775,-0.014927304790655724,0.024754307765211286,0.07938215827712267,0.028559168616551125]\n",
      "\u001b[1mIntercept: \u001b[0m 0.2853059211165923 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.02906255004631339,0.008573954958926076,-0.07756454993797456,0.0018588255667291661,-0.020490593967404745,-0.10594430192809773,-0.06590565948149969,-0.030486623008660667,-0.020037390183579442,-0.04122018281388537,0.051253381352657494,-0.027358033021736353,0.004876058926356586,-0.001901812510827591,-0.02461061967061981,-0.031235391961720264,0.014927304800791196,-0.024754307774307156,-0.07938215830519414,-0.02855916862033397]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.053583012838006455,0.10277940591780314,-0.2830890181922616,0.0531995475043727,-0.03426643262959213,-0.32590038270171645,-0.21349854550695166,-0.06033946397748267,-0.03314556333036332,-0.12722300370689357,0.17749351784095488,-0.08352688991680594,0.08577628422768771,0.043017773471279074,-0.052145959446003816,-0.07949468992829013,0.11955391484037912,-0.0570504813543225,-0.28533504881245453,-0.06691551100478156]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04333256370668551,0.042073590631561984,0.06459222740672979,0.05024654646373073,0.038292039091364034,0.10017125371596977,0.06390622553586152,0.045281860771362537,0.04696806298902881,0.03754484643479208,0.05665145210483223,0.043217048843819925,0.04585748754878506,0.04808593532413934,0.04250764393598294,0.04618545806276296,0.040791520096186626,0.04483888035790137,0.057089629410584694,0.042365727567918204])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.045793352345342694,0.046385689389778224,0.053545882621975294,0.04420047367447818,0.03933848353190704,0.05936899595596281,0.06527284838582866,0.0589025407946331,0.04194216711224322,0.05095220066218792,0.05268579586507673,0.042341087141434613,0.0508749221082824,0.048112387432248355,0.053899434104716114,0.054260287320867365,0.04261459604732335,0.0604967276919638,0.04347482183691867,0.04553730597683115])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[2,5,6,7,8,9,10,14,15,16,18,19],[0.1987574515815474,0.42379132584968066,0.054789312555477566,0.011583673084970826,0.00964070138018111,0.014601984945154918,0.06137775000041815,0.018668316997740773,0.014774147889243224,0.01747007254603732,0.15671802239116323,0.0178272407783849])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |52.98 |\n",
      "|OneVsRest                     |53.00 |\n",
      "|LinearSVC                     |53.02 |\n",
      "|NaiveBayes                    |52.81 |\n",
      "|RandomForestClassifier        |53.17 |\n",
      "|GBTClassifier                 |53.05 |\n",
      "|DecisionTreeClassifier        |52.80 |\n",
      "|MultilayerPerceptronClassifier|53.03 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "\u001b[1mTFIDFfeaturizedData  Results:\u001b[0m\n",
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.0408354 ,  0.00887862, -0.09103287,  0.00210003, -0.02354744,\n",
      "              -0.14421091, -0.08752417, -0.04289742, -0.02650645, -0.04881141,\n",
      "               0.07020215, -0.02894503,  0.00510917, -0.00379334, -0.03224649,\n",
      "              -0.03951824,  0.01539551, -0.0350448 , -0.08656449, -0.03312083]])\n",
      "Intercept: [0.30282645290315496]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -0.28530592112109104 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.03871309438125577,-0.009103311048039827,0.08700072148924612,-0.0027957872742389563,0.022223468305801002,0.1382251466445809,0.08361214340128541,0.04085175886785104,0.02504863702794812,0.04631244422115283,-0.06801086143327446,0.027299942301428105,-0.005593808209216521,0.002881992388550799,0.030388708632746016,0.0373683940552903,-0.015199831726298582,0.03315045924398173,0.08284827870867717,0.031324941632874234]\n",
      "\u001b[1mIntercept: \u001b[0m 0.28530592112109193 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.03871309438125584,0.009103311048039856,-0.08700072148924631,0.002795787274238754,-0.022223468305800912,-0.13822514664458094,-0.08361214340128517,-0.0408517588678518,-0.025048637027948142,-0.04631244422115298,0.06801086143327388,-0.02729994230142803,0.005593808209215962,-0.0028819923885510658,-0.03038870863274587,-0.03736839405529022,0.01519983172629861,-0.03315045924398148,-0.08284827870867699,-0.03132494163287445]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.07137585073160913,0.10912500783679847,-0.31752841800987436,0.08001537141742264,-0.037164319442245915,-0.42520104797045377,-0.2708579376825961,-0.08085425635937606,-0.041435095961750754,-0.14293988677499958,0.23552567137875038,-0.08334953299382189,0.09840243747349492,0.0651888106292963,-0.06438880409572102,-0.09510330149510832,0.12173660371238147,-0.07640082990500296,-0.2977938388478018,-0.07339585072318697]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04333256370668551,0.042073590631561984,0.06459222740672979,0.05024654646373073,0.038292039091364034,0.10017125371596977,0.06390622553586152,0.045281860771362537,0.04696806298902881,0.03754484643479208,0.05665145210483223,0.043217048843819925,0.04585748754878506,0.04808593532413934,0.04250764393598294,0.04618545806276296,0.040791520096186626,0.04483888035790137,0.057089629410584694,0.042365727567918204])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.045793352345342694,0.046385689389778224,0.053545882621975294,0.04420047367447818,0.03933848353190704,0.05936899595596281,0.06527284838582866,0.0589025407946331,0.04194216711224322,0.05095220066218792,0.05268579586507673,0.042341087141434613,0.0508749221082824,0.048112387432248355,0.053899434104716114,0.054260287320867365,0.04261459604732335,0.0604967276919638,0.04347482183691867,0.04553730597683115])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[2,5,6,7,8,9,10,14,15,16,18,19],[0.1987574515815474,0.42379132584968066,0.054789312555477566,0.011583673084970826,0.00964070138018111,0.014601984945154918,0.06137775000041815,0.018668316997740773,0.014774147889243224,0.01747007254603732,0.15671802239116323,0.0178272407783849])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |52.98 |\n",
      "|OneVsRest                     |53.00 |\n",
      "|LinearSVC                     |53.02 |\n",
      "|NaiveBayes                    |52.82 |\n",
      "|RandomForestClassifier        |53.17 |\n",
      "|GBTClassifier                 |53.05 |\n",
      "|DecisionTreeClassifier        |52.80 |\n",
      "|MultilayerPerceptronClassifier|53.21 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "\u001b[1mW2VfeaturizedData  Results:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-1.46814012, -2.08760991,  1.67904552]])\n",
      "\n",
      "Intercept: [0.8591362555621951]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -0.8242872605947403 \u001b[1m\n",
      "Coefficients:\u001b[0m [1.4663704020370643,1.7656907897071104,-1.4457105513452693]\n",
      "\u001b[1mIntercept: \u001b[0m 0.8242872605947139 \u001b[1m\n",
      "Coefficients:\u001b[0m [-1.466370402036972,-1.7656907897076197,1.4457105513457007]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-3.7676302207664802,-0.5523437888570654,3.9370610791680343]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.5071489613734215,0.1456359944669451,0.3472150441596334])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.3505880539980437,0.24898888850872486,0.4004230574932315])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.470484011748621,0.058488604057017966,0.4710273841943611])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 39\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |55.04 |\n",
      "|OneVsRest                     |55.20 |\n",
      "|LinearSVC                     |53.55 |\n",
      "|NaiveBayes                    |50.54 |\n",
      "|RandomForestClassifier        |57.07 |\n",
      "|GBTClassifier                 |57.30 |\n",
      "|DecisionTreeClassifier        |57.31 |\n",
      "|MultilayerPerceptronClassifier|57.34 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for featureDF in featureDF_list:\n",
    "    print('\\033[1m' + featureDF.name,\" Results:\"+ '\\033[0m')\n",
    "    train, test = featureDF.randomSplit([0.7, 0.3],seed = 11)\n",
    "    features = featureDF.select(['features']).collect()\n",
    "    # Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "    class_count = featureDF.select(countDistinct(\"label\")).collect()\n",
    "    classes = class_count[0][0]\n",
    "\n",
    "    #set up your results table\n",
    "    columns = ['Classifier', 'Result']\n",
    "    vals = [(\"Place Holder\",\"N/A\")]\n",
    "    results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        new_result = ClassTrainEval(classifier,features,classes,train,test)\n",
    "        results = results.union(new_result)\n",
    "    results = results.where(\"Classifier!='Place Holder'\")\n",
    "    print(results.show(truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing best model and prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.470484011748621,0.058488604057017966,0.4710273841943611])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Classifier: string, Result: string]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "featureDF = W2VfeaturizedData\n",
    "\n",
    "train, test = featureDF.randomSplit([0.7, 0.3],seed = 11)\n",
    "features = featureDF.select(['features']).collect()\n",
    "\n",
    "# Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "class_count = featureDF.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "\n",
    "ClassTrainEval(classifier,features,classes,train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally checking the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failures:\n",
      "+------+-----------------------------------------------+\n",
      "|state |blurb                                          |\n",
      "+------+-----------------------------------------------+\n",
      "|failed| a silent baby monitor that improves your sleep|\n",
      "|failed| ac                                            |\n",
      "|failed| big peace of mind                             |\n",
      "+------+-----------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      " \n",
      "Success:\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|state |blurb                                                                                                                        |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|failed| a pixel recreating this story through kickstarter for an even bigger and more memorable viral storyand you can be part of it|\n",
      "|failed| accurate weather app that gives you exact temperatures from your exact location simply click scan to get mi temp            |\n",
      "|failed| all you need is love lets illuminate the idea shed light on the universal answer and brighten up someones day               |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = DT_BestModel.transform(test)\n",
    "print(\"Failures:\")\n",
    "predictions.select(\"state\",\"blurb\").filter(\"prediction=0\").orderBy(predictions[\"prediction\"].desc()).show(3,False)\n",
    "print(\" \")\n",
    "print(\"Success:\")\n",
    "predictions.select(\"state\",\"blurb\").filter(\"prediction=1\").orderBy(predictions[\"prediction\"].desc()).show(3,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final past is just copy and paste, there is not much to change, cause content is really high quality one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The End***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
