{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with MLlib and PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This reference material will take a closer look to classification with MLlib. In fact the whole process of training, testing and evaluating is almost identical to Scikit Learn. Only difference is data preparation which is handled with PySpark.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable pre-processing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- String Indexer functin (better for ordinal)\n",
    "- IndexToString -> transforms string labels back to the indexes\n",
    "- OneHotEncoderEstimator better for nonimal and is also in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier in PySpark:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LogisticRegression\n",
    "- Decision Tree\n",
    "- Ensemble Methods (Random Forest - bagging, Gradient-Boosting)\n",
    "- Boosting is learning from previous mistakes -> sequential\n",
    "- Bagging is parallel and then chooses the best result\n",
    "- Multilayer Perceptron Classifier (MLP)\n",
    "- Linear SVM\n",
    "- One vs Rest classifier (each class is comparing against an entire datasets)\n",
    "- Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Class\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.36:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Class</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x26b87afd820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Basic Imports and data load</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import*\n",
    "from pyspark.sql. functions import*\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autistic Spectrum Disorder Screening Data for Adult**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autistic Spectrum Disorder (ASD) is a neurodevelopment condition associated with significant healthcare costs, and early diagnosis can significantly reduce these. Unfortunately, waiting times for an ASD diagnosis are lengthy and procedures are not cost effective. The economic impact of autism and the increase in the number of ASD cases across the world reveals an urgent need for the development of easily implemented and effective screening methods. Therefore, a time-efficient and accessible ASD screening is imminent to help health professionals and inform individuals whether they should pursue formal clinical diagnosis. The rapid growth in the number of ASD cases worldwide necessitates datasets related to behaviour traits. However, such datasets are rare making it difficult to perform thorough analyses to improve the efficiency, sensitivity, specificity and predictive accuracy of the ASD screening process. Presently, very limited autism datasets associated with clinical or screening are available and most of them are genetic in nature. Hence, we propose a new dataset related to autism screening of adults that contained 20 features to be utilised for further analysis especially in determining influential autistic traits and improving the classification of ASD cases. In this dataset, we record ten behavioural features (AQ-10-Adult) plus ten individuals characteristics that have proved to be effective in detecting the ASD cases from controls in behaviour science.\n",
    "\n",
    "\n",
    "**Source:** https://www.kaggle.com/faizunnabi/autism-screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"Datasets/Toddler Autism dataset July 2018.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Data preparation</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|Class/ASD Traits |count|\n",
      "+-----------------+-----+\n",
      "|               No|  326|\n",
      "|              Yes|  728|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Class/ASD Traits \").count().show()\n",
    "#checking labels if we have imbalanced data or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Firstly we wanna drop label and id.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = df.columns\n",
    "input_columns = input_columns[1:-1] #first and last out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons', 'Qchat-10-Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test']\n"
     ]
    }
   ],
   "source": [
    "print(input_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_var = \"Class/ASD Traits \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed = df.withColumn(\"label_str\", df[label_var].cast(StringType())) #changing data type of our data\n",
    "indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #string indexing\n",
    "indexed = indexer.fit(renamed).transform(renamed) #fitting - only for our label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now dealing with other columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = []\n",
    "string_inputs = []\n",
    "\n",
    "for column in input_columns: #iterate through our columns\n",
    "    if str(indexed.schema[column].dataType) == \"StringType\": #if data typ is string we wanna change that\n",
    "        indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\") #changing and adding _num to name\n",
    "        indexed = indexer.fit(indexed).transform(indexed) #fitting and transforming\n",
    "        new_col_name = column+\"_num\"\n",
    "        string_inputs.append(new_col_name) #appending to our string list\n",
    "    else:\n",
    "        numeric_inputs.append(column) #appending to our numeric list if column is numeric already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "      <th>label_str</th>\n",
       "      <th>label</th>\n",
       "      <th>Sex_num</th>\n",
       "      <th>Ethnicity_num</th>\n",
       "      <th>Jaundice_num</th>\n",
       "      <th>Family_mem_with_ASD_num</th>\n",
       "      <th>Who completed the test_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  ...  Family_mem_with_ASD  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0  ...                   no   \n",
       "1        2   1   1   0   0   0   1   1   0   0  ...                   no   \n",
       "2        3   1   0   0   0   0   0   1   1   0  ...                   no   \n",
       "3        4   1   1   1   1   1   1   1   1   1  ...                   no   \n",
       "4        5   1   1   0   1   1   1   1   1   1  ...                  yes   \n",
       "\n",
       "   Who completed the test  Class/ASD Traits  label_str label Sex_num  \\\n",
       "0           family member                 No        No   1.0     1.0   \n",
       "1           family member                Yes       Yes   0.0     0.0   \n",
       "2           family member                Yes       Yes   0.0     0.0   \n",
       "3           family member                Yes       Yes   0.0     0.0   \n",
       "4           family member                Yes       Yes   0.0     1.0   \n",
       "\n",
       "  Ethnicity_num Jaundice_num Family_mem_with_ASD_num  \\\n",
       "0           2.0          1.0                     0.0   \n",
       "1           0.0          1.0                     0.0   \n",
       "2           2.0          1.0                     0.0   \n",
       "3           5.0          0.0                     0.0   \n",
       "4           0.0          0.0                     1.0   \n",
       "\n",
       "  Who completed the test_num  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So my numeric columns are twice here, in string format and in numeric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>BeAware:</b>It's only tutorial, but I would probably care more about nominal and ordinal encoding</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier deletion- measuring of skewness - tough one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for col in numeric_inputs:\n",
    "    d[col] = indexed.approxQuantile(col,[0.01,0.99],0.25)\n",
    "    #we will go throug our columns and use approxQuantile function we wanna first and last percent of data\n",
    "    \n",
    "for col in numeric_inputs:\n",
    "    skew = indexed.agg(skewness(indexed[col])).collect() #skeweness measure skew\n",
    "    #I am aggregating skewness scores from our columns\n",
    "    skew= skew[0][0] #first row and first column\n",
    "    if skew > 1:\n",
    "        indexed = indexed.withColumn(col, log(when(d[col]< d[col][0],d[col][0])\\\n",
    "                                             .when(indexed[col]> df[col][1], df[col][1])\\\n",
    "                                             .otherwise(indexed[col])+1).alias(col))\n",
    "        print(col,\"has been treader for pos skew\", skew)\n",
    "    elif skew <-1:\n",
    "        indexed = indexed.withColumn(col, exp(when(d[col]< d[col][0],d[col][0])\\\n",
    "                                             .when(indexed[col]> d[col][1], d[col][1])\\\n",
    "                                             .otherwise(indexed[col]).alias(col)))\n",
    "        print(col,\"has been treader for negativ skew\", skew)\n",
    "#hmm pretty crazy function but very handy - measures skewness of data and repair them - it is basically deleting\n",
    "#top and bottom tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Negativ values detector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimus = df.select([min(c).alias(c) for c in df.columns if c in numeric_inputs])\n",
    "#it just collect minimum values for our numeric inputs - for each col one value\n",
    "min_array = minimus.select(array(numeric_inputs).alias(\"mins\"))\n",
    "#after that I am creating array from that\n",
    "df_minimum = min_array.select(array_min(min_array.mins)).collect()\n",
    "df_minimum = df_minimum[0][0]\n",
    "#hmm I consider that as a weird syntax and over complicated ..it's just for checking negativ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                mins|\n",
      "+--------------------+\n",
      "|[0, 0, 0, 0, 0, 0...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_array.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating our features - VectorAssembler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = numeric_inputs + string_inputs #just a list of my features\n",
    "#string inputs are also numerical already.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'Age_Mons',\n",
       " 'Qchat-10-Score',\n",
       " 'Sex_num',\n",
       " 'Ethnicity_num',\n",
       " 'Jaundice_num',\n",
       " 'Family_mem_with_ASD_num',\n",
       " 'Who completed the test_num']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list #something like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=feature_list, outputCol=\"features\")\n",
    "#it is jus VectorAssembler ..joining columns together\n",
    "output = assembler.transform(indexed).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(17,[6,7,9,10,11,...|  1.0|\n",
      "|(17,[0,1,5,6,10,1...|  0.0|\n",
      "|(17,[0,6,7,9,10,1...|  0.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,0.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,0.0,0.0,...|  0.0|\n",
      "|(17,[0,3,4,5,8,10...|  0.0|\n",
      "|(17,[1,4,6,7,8,9,...|  0.0|\n",
      "|(17,[6,9,10,11,13...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "|[1.0,0.0,0.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|(17,[10,12,13,14]...|  1.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|(17,[10,13],[18.0...|  1.0|\n",
      "|(17,[0,1,2,4,6,7,...|  0.0|\n",
      "|(17,[10,13,15],[3...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "|(17,[0,4,9,10,11,...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show() #my data are now only in two columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", min=0, max=1000)\n",
    "#we are setting min to 0 because we don't wanna zero values\n",
    "scalerModel = scaler.fit(output)\n",
    "scaled_data = scalerModel.transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|      scaledFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|(17,[6,7,9,10,11,...|  1.0|(17,[6,7,9,10,11,...|\n",
      "|(17,[0,1,5,6,10,1...|  0.0|(17,[0,1,5,6,10,1...|\n",
      "|(17,[0,6,7,9,10,1...|  0.0|(17,[0,6,7,9,10,1...|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|[1000.0,1000.0,10...|\n",
      "|[1.0,1.0,0.0,1.0,...|  0.0|[1000.0,1000.0,0....|\n",
      "|[1.0,1.0,0.0,0.0,...|  0.0|[1000.0,1000.0,0....|\n",
      "|(17,[0,3,4,5,8,10...|  0.0|(17,[0,3,4,5,8,10...|\n",
      "|(17,[1,4,6,7,8,9,...|  0.0|(17,[1,4,6,7,8,9,...|\n",
      "|(17,[6,9,10,11,13...|  1.0|(17,[6,9,10,11,13...|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|[1000.0,1000.0,10...|\n",
      "|[1.0,0.0,0.0,1.0,...|  0.0|[1000.0,0.0,0.0,1...|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|[1000.0,1000.0,10...|\n",
      "|(17,[10,12,13,14]...|  1.0|(17,[10,12,13,14]...|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|[1000.0,1000.0,10...|\n",
      "|(17,[10,13],[18.0...|  1.0|(17,[10,13],[250....|\n",
      "|(17,[0,1,2,4,6,7,...|  0.0|(17,[0,1,2,4,6,7,...|\n",
      "|(17,[10,13,15],[3...|  1.0|(17,[10,13,15],[1...|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|[1000.0,1000.0,10...|\n",
      "|(17,[0,4,9,10,11,...|  1.0|(17,[0,4,9,10,11,...|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|(17,[0,1,2,4,6,7,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = scaled_data.select(\"label\",\"scaledFeatures\")\n",
    "final_data = final_data.withColumnRenamed(\"scaledFeatures\",\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(17,[6,7,9,10,11,...|\n",
      "|  0.0|(17,[0,1,5,6,10,1...|\n",
      "|  0.0|(17,[0,6,7,9,10,1...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  0.0|[1000.0,1000.0,0....|\n",
      "|  0.0|[1000.0,1000.0,0....|\n",
      "|  0.0|(17,[0,3,4,5,8,10...|\n",
      "|  0.0|(17,[1,4,6,7,8,9,...|\n",
      "|  1.0|(17,[6,9,10,11,13...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  0.0|[1000.0,0.0,0.0,1...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  1.0|(17,[10,12,13,14]...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  1.0|(17,[10,13],[250....|\n",
      "|  0.0|(17,[0,1,2,4,6,7,...|\n",
      "|  1.0|(17,[10,13,15],[1...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  1.0|(17,[0,4,9,10,11,...|\n",
      "|  0.0|(17,[0,1,2,4,6,7,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just deleting features and renaming scaledfeatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = final_data.randomSplit([0.7,0.3]) #70% and 30% random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 334)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count(), test.count() #weird that its not len :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I will focus on some classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> this part contains basic info for every PySpark classifier and how to use it. Some parts are just copy and paste, it's more a quick refresher of PySpark</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Training, testing and predicting</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") #for metric measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression() #my classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [10, 15,20]).build())\n",
    "#setting up my hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MC_evaluator,\n",
    "                          numFolds=3) \n",
    "#my cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitModel = crossval.fit(train) #fitting my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestModel = fitModel.bestModel #looking for the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [53.328829302256686]\n",
      "Coefficients: \n",
      "DenseMatrix([[-1.18950832e-02, -1.10041935e-02, -1.15087043e-02,\n",
      "              -1.14871367e-02, -1.14903526e-02, -1.12813030e-02,\n",
      "              -1.17502752e-02, -1.13838220e-02, -1.17504639e-02,\n",
      "              -1.16707740e-02, -1.26690894e-03, -3.29165767e-02,\n",
      "              -4.95346691e-05, -4.13318562e-04, -8.41729898e-04,\n",
      "               2.81695294e-04, -8.28203670e-03]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "#printing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fitModel.transform(test) #now I am only using transform for my test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (MC_evaluator.evaluate(predictions))*100 #and I am evaluating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Feature importance</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|             feature|               coeff|\n",
      "+--------------------+--------------------+\n",
      "|                  A1|-0.01189508322066376|\n",
      "|                  A2|-0.01100419352374...|\n",
      "|                  A3|-0.01150870434067...|\n",
      "|                  A4|-0.01148713670676...|\n",
      "|                  A5|-0.01149035258499...|\n",
      "|                  A6|-0.01128130300534...|\n",
      "|                  A7|-0.01175027522635...|\n",
      "|                  A8|-0.01138382202587...|\n",
      "|                  A9|-0.01175046394679...|\n",
      "|                 A10|-0.01167077403238...|\n",
      "|            Age_Mons|-0.00126690893723...|\n",
      "|      Qchat-10-Score|-0.03291657674658315|\n",
      "|                 Sex|-4.95346690839824...|\n",
      "|           Ethnicity|-4.13318562236252...|\n",
      "|            Jaundice|-8.41729897833716...|\n",
      "| Family_mem_with_ASD|2.816952939039711E-4|\n",
      "|Who completed the...|-0.00828203669800...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coeff_array = BestModel.coefficientMatrix.toArray() #coefficient to array from my best model\n",
    "\n",
    "#Now i just want my array transform to list\n",
    "coeff_scores = []\n",
    "for x in coeff_array[0]:\n",
    "    coeff_scores.append(float(x))\n",
    "    \n",
    "result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is probably all. It's just for educational purpose, we have only small part of original dataset so our accuracy is a little twisted :). For feature importance and ocefficient interpretation is a good article here: ***https://www.displayr.com/how-to-interpret-logistic-regression-coefficients/***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Training, testing and predicting</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each class is viewed as it compares to rest of the classes as a whole, as opposed to each one individually. It's not a new estimator just another form of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression() #creating another logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = OneVsRest(classifier=lr) #now creating classifier with one classifier within :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]).build() #just parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=classifier, #our estimator\n",
    "                          estimatorParamMaps=paramGrid, #our parameters\n",
    "                          evaluator=MulticlassClassificationEvaluator(), #our evaluator\n",
    "                          numFolds=5)  #and number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitModel = crossval.fit(train) #training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestModel = fitModel.bestModel #looking for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = BestModel.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.393831841017095 [0.0014856949899890567,0.001688943775857319,0.0013360474103731505,0.001500978245841736,0.0017346188604542082,0.0015081235053492706,0.0016205494908386193,0.0017214085038386787,0.0018115385933320709,0.0014320087455013677,0.00036832670335998086,0.004529542675628303,-0.00035002916340941753,0.0006321027175696799,0.0005038737980106367,2.4629920556283505e-05,0.000713711595807801]\n",
      "7.393831840565555 [-0.0014856949899168701,-0.0016889437758628824,-0.0013360474103949645,-0.0015009782458118468,-0.0017346188602188075,-0.00150812350531691,-0.0016205494911018564,-0.0017214085034702915,-0.0018115385930456763,-0.0014320087454208646,-0.00036832670332823163,-0.004529542675385013,0.000350029163575465,-0.0006321027176559,-0.0005038737980327789,-2.462992072611913e-05,-0.0007137115964014607]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model.intercept, model.coefficients)\n",
    "    \n",
    "#just printing coefficients..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fitModel.transform(test)#predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (MC_evaluator.evaluate(predictions))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again the result is not an important here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptro Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Aka Neural Network. Basic info is here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Common Hyper Parameters:***\n",
    "\n",
    "**MaxIter:** <br>\n",
    "The maximum number of iterations to use. There is no clear formula for setting the optimum iteration number, but you can figure out this issue by an iterative process by initializing the iteration number by a small number like 100 and then increase it linearly. This process will be repeated until the MSE of the test does not decrease and even may increase. The below link describes well:\n",
    "https://www.quora.com/What-will-happen-if-I-train-my-neural-networks-with-too-much-iteration\n",
    "\n",
    "**Layers:** <br>\n",
    "Spark requires that the input layer equals the number of features in the dataset, the hidden layer might be one or two more than that (flexible), and the output layer has to be equal to the number of classes. Here's a great article to learn more about how to play around with the hidden layers: https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e\n",
    "\n",
    "**Block size:** <br>\n",
    "Block size for stacking input data in matrices to speed up the computation. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data. Recommended size is between 10 and 1000. Default: 128\n",
    "\n",
    "**Seed:** <br>\n",
    "A random seed. Set this value if you need your results to be reproducible across repeated calls (highly recommdended).\n",
    "\n",
    "**Weights**: *printed for us below along with accuracy rate* <br> \n",
    "Each hidden neuron added will increase the number of weights, thus it is recommended to use the least number of hidden neurons that accomplish the task. Using more hidden neurons than required will add more complexity.\n",
    "\n",
    "**PySpark Documentation link:** <br> \n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683\n",
      "Accuracy:  90.71856287425149\n"
     ]
    }
   ],
   "source": [
    "#Firstly collecting features and classes numbers\n",
    "features = final_data.select(['features']).collect() #counting the features\n",
    "features_count = len(features[0][0])\n",
    "\n",
    "class_count = final_data.select(countDistinct(\"label\")).collect() #counting the classes\n",
    "classes = class_count[0][0]\n",
    "\n",
    "layers = [features_count, features_count+1, features_count, classes]\n",
    "#FEATURES - HIDDEN LAYERS - SECOND HIDDEN LAYER - CLASSES\n",
    "#Note: hidden layer has to be equal to feature or +1,+2 in PySPark\n",
    "\n",
    "classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "#our classifier\n",
    "\n",
    "fitModel = classifier.fit(train) #training our data\n",
    "print(fitModel.weights.size) # Print the model Weights\n",
    "predictions = fitModel.transform(test) #predicting\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100 #accuracy\n",
    "print(\"Accuracy: \",accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Basic Info***\n",
    "\n",
    "**Assumptions:**\n",
    " - Independence between every pair of features\n",
    " - Feature values are nonnegative (which is why we checked earlier)\n",
    "\n",
    "**Hyper Parameters:**\n",
    "\n",
    " - **smoothing** = It is problematic when a frequency-based probability is zero, because it will wipe out all the information in the other probabilities, and we need to find a solution for this. A solution would be Laplace smoothing , which is a technique for smoothing categorical data. In PySpark, this number needs to be be >= 0, default is 1.0'. Also here is a great article that defines smoothing in more detail: https://medium.com/syncedreview/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation-4f5271768ebf\n",
    " - **thresholds** = Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. The default value is none. \n",
    " - **weightCol** = If you have a weight column you would enter the name of the column here. If this is not set or empty, we treat all instance weights as 1.0. To learn more about the theory behind this, here is a good paper: http://pami.uwaterloo.ca/~khoury/ece457f07/Zhang2004.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  85.02994011976048\n"
     ]
    }
   ],
   "source": [
    "#Still the same\n",
    "classifier = NaiveBayes()\n",
    "paramGrid = (ParamGridBuilder().addGrid(classifier.smoothing, [0.0, 0.3, 0.7, 0.8]).build())\n",
    "\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "fitModel = crossval.fit(train)\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Basic info***\n",
    "\n",
    "**Interpretting the coefficients:**\n",
    "\n",
    "Each coefficients direction gives us the predicted class, so if you take the dot product of any point with the vector, you can tell on which side it is: if the dot product is positive, it belongs to the positive class, if it is negative it belongs to the negative class.\n",
    "\n",
    "You can even learn something about the importance of each feature. Let's say the svm would find only one feature useful for separating the data, then the hyperplane would be orthogonal to that axis. So, you could say that the absolute size of the coefficient relative to the other ones gives an indication of how important the feature was for the separation. \n",
    "\n",
    "**Hyper Parameters:** <br>\n",
    "\n",
    "**MaxIter:** <br>\n",
    "The maximum number of iterations to use. There is no clear formula for setting the optimum iteration number, but you can figure out this issue by an iterative process by initializing the iteration number by a small number like 100 and then increase it linearly. This process will be repeated until the MSE of the test does not decrease and even may increase. The below link describes well:\n",
    "https://www.quora.com/What-will-happen-if-I-train-my-neural-networks-with-too-much-iteration\n",
    "\n",
    "**regParam**: <br>\n",
    "The purpose of the regularizer is to encourage simple models and avoid overfitting. To learn more about this concept, here is an interesting article: https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a\n",
    "\n",
    "**PySpark Documentation link:** <br> https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "#Just a small \"checker\" \n",
    "class_count = final_data.select(countDistinct(\"label\")).collect() #I am counting unique classes values\n",
    "classes = class_count[0][0] #pulling only number\n",
    "if classes > 2:\n",
    "    print(\"LinearSVC cannot be used because PySpark currently only accepts\\\n",
    "          binary classification data for this algorithm\")\n",
    "\n",
    "classifier = LinearSVC()\n",
    "paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [15, 50]).addGrid(classifier.regParam, [0.2, 0.01]).build())\n",
    "\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "\n",
    "#Fitting and predicting\n",
    "fitModel = crossval.fit(train)\n",
    "BestModel = fitModel.bestModel\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Basic Info***\n",
    "**Common Hyper Parameters**\n",
    "\n",
    " - **maxBins** = Max number of bins for discretizing continuous features. Must be >=2 and >= number of categories for any categorical feature.\n",
    "     - **Continuous features:** For small datasets in single-machine implementations, the split candidates for each continuous feature are typically the unique values for the feature. Some implementations sort the feature values and then use the ordered unique values as split candidates for faster tree calculations.\n",
    "         Sorting feature values is expensive for large distributed datasets. This implementation computes an approximate set of split candidates by performing a quantile calculation over a sampled fraction of the data. The ordered splits create â€œbinsâ€ and the maximum number of such bins can be specified using the maxBins parameter.\n",
    "         Note that the number of bins cannot be greater than the number of instances N (a rare scenario since the default maxBins value is 32). The tree algorithm automatically reduces the number of bins if the condition is not satisfied.\n",
    "\n",
    "     - **Categorical features:** For a categorical feature with M possible values (categories), one could come up with 2 exp(Mâˆ’1) âˆ’1 split candidates. For binary (0/1) classification and regression, we can reduce the number of split candidates to Mâˆ’1 by ordering the categorical feature values by the average label. For example, for a binary classification problem with one categorical feature with three categories A, B and C whose corresponding proportions of label 1 are 0.2, 0.6 and 0.4, the categorical features are ordered as A, C, B. The two split candidates are A | C, B and A , C | B where | denotes the split.\n",
    "         In multiclass classification, all 2 exp(Mâˆ’1) âˆ’1 possible splits are used whenever possible. When 2 exp(Mâˆ’1) âˆ’1 is greater than the maxBins parameter, we use a (heuristic) method similar to the method used for binary classification and regression. The M categorical feature values are ordered by impurity, and the resulting Mâˆ’1 split candidates are considered.\n",
    "         \n",
    " - **maxDepth** = The max_depth parameter specifies the maximum depth of each tree. The default value for max_depth is None, which means that each tree will expand until every leaf is pure. A pure leaf is one where all of the data on the leaf comes from the same class.\n",
    "\n",
    "### Feature Importance Scores\n",
    "Scores add up to 1 accross all varaibles so the lowest score is the least imporant variable. \n",
    "\n",
    "\n",
    "### Extra Reading\n",
    "**How to tune a decision tree** <br>\n",
    "https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n",
    "\n",
    "**PySpark Documentation link:** <br> https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "paramGrid = (ParamGridBuilder().addGrid(classifier.maxBins, [10, 20, 40, 80, 100]).build())\n",
    "#note I wont be using more parameters - BUT I SHOULD, for this case I just don't wanna waste time computing..\n",
    "\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=3) \n",
    "\n",
    "\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Feature importance - important\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now nicer looking feature importance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|feature               |score|\n",
      "+----------------------+-----+\n",
      "|Qchat-10-Score        |1    |\n",
      "|A9                    |0    |\n",
      "|Age_Mons              |0    |\n",
      "|A10                   |0    |\n",
      "|Family_mem_with_ASD   |0    |\n",
      "|Sex                   |0    |\n",
      "|Ethnicity             |0    |\n",
      "|Jaundice              |0    |\n",
      "|A3                    |0    |\n",
      "|Who completed the test|0    |\n",
      "|A5                    |0    |\n",
      "|A6                    |0    |\n",
      "|A7                    |0    |\n",
      "|A8                    |0    |\n",
      "|A1                    |0    |\n",
      "|A2                    |0    |\n",
      "|A4                    |0    |\n",
      "+----------------------+-----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "imp_scores = []\n",
    "for x in featureImportances:\n",
    "    imp_scores.append(int(x))\n",
    "    \n",
    "# Then zip with input_columns list and create a df\n",
    "result = spark.createDataFrame(zip(input_columns,imp_scores), schema=['feature','score'])\n",
    "print(result.orderBy(result[\"score\"].desc()).show(truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>BeAware:</b>it is a good habbit to run Tree at the beginning of project and to look at what features are more improtant than others, and therefore we can pay more attention to them in the analysis</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Basic info is same as for Decisions Tree. Just stacking the trees!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark Documentation link: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.07954638 0.01880797 0.         0.02694263 0.18578089 0.13816786\n",
      " 0.10158916 0.01076742 0.04391258 0.         0.         0.39394903\n",
      " 0.         0.00053607 0.         0.         0.        ]\n",
      " \n",
      "Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "#Still the same\n",
    "classifier = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "             .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2)\n",
    "\n",
    "\n",
    "fitModel = crossval.fit(train)\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Tree CLassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Same info as for Tree and Forrest but now we are boosting. Learning from each other!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark Documentation link: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.00000000e+00 8.49404185e-17 2.16993702e-18 0.00000000e+00\n",
      " 0.00000000e+00 8.47789349e-19 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.58373897e-17 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.78815931e-15]\n",
      " \n",
      "Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "#Again and again :)\n",
    "classifier = GBTClassifier()\n",
    "\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "             .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) \n",
    "\n",
    "\n",
    "fitModel = crossval.fit(train)\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)   \n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> I could iterate through all classifiers but that is not a point here.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips & Tricks for reducing redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Data preparation function</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying and pasting, its just all data preparation rewritten in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep function\n",
    "def MLClassifierDFPrep(df,input_columns,dependent_var,treat_outliers=True,treat_neg_values=True):\n",
    "    \n",
    "    # change label (class variable) to string type to prep for reindexing\n",
    "    # Pyspark is expecting a zero indexed integer for the label column. \n",
    "    # Just incase our data is not in that format... we will treat it by using the StringIndexer built in method\n",
    "    renamed = df.withColumn(\"label_str\", df[dependent_var].cast(StringType())) #Rename and change to string type\n",
    "    indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #Pyspark is expecting the this naming convention \n",
    "    indexed = indexer.fit(renamed).transform(renamed)\n",
    "\n",
    "    # Convert all string type data in the input column list to numeric\n",
    "    # Otherwise the Algorithm will not be able to process it\n",
    "    numeric_inputs = []\n",
    "    string_inputs = []\n",
    "    for column in input_columns:\n",
    "        if str(indexed.schema[column].dataType) == 'StringType':\n",
    "            indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\") \n",
    "            indexed = indexer.fit(indexed).transform(indexed)\n",
    "            new_col_name = column+\"_num\"\n",
    "            string_inputs.append(new_col_name)\n",
    "        else:\n",
    "            numeric_inputs.append(column)\n",
    "            \n",
    "    if treat_outliers == True:\n",
    "        print(\"We are correcting for non normality now!\")\n",
    "        # empty dictionary d\n",
    "        d = {}\n",
    "        # Create a dictionary of quantiles\n",
    "        for col in numeric_inputs: \n",
    "            d[col] = indexed.approxQuantile(col,[0.01,0.99],0.25) #if you want to make it go faster increase the last number\n",
    "        #Now fill in the values\n",
    "        for col in numeric_inputs:\n",
    "            skew = indexed.agg(skewness(indexed[col])).collect() #check for skewness\n",
    "            skew = skew[0][0]\n",
    "            # This function will floor, cap and then log+1 (just in case there are 0 values)\n",
    "            if skew > 1:\n",
    "                indexed = indexed.withColumn(col, \\\n",
    "                log(when(df[col] < d[col][0],d[col][0])\\\n",
    "                .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "                .otherwise(indexed[col] ) +1).alias(col))\n",
    "                print(col+\" has been treated for positive (right) skewness. (skew =)\",skew,\")\")\n",
    "            elif skew < -1:\n",
    "                indexed = indexed.withColumn(col, \\\n",
    "                exp(when(df[col] < d[col][0],d[col][0])\\\n",
    "                .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "                .otherwise(indexed[col] )).alias(col))\n",
    "                print(col+\" has been treated for negative (left) skewness. (skew =\",skew,\")\")\n",
    "\n",
    "            \n",
    "    # Produce a warning if there are negative values in the dataframe that Naive Bayes cannot be used. \n",
    "    # Note: we only need to check the numeric input values since anything that is indexed won't have negative values\n",
    "    minimums = df.select([min(c).alias(c) for c in df.columns if c in numeric_inputs]) # Calculate the mins for all columns in the df\n",
    "    min_array = minimums.select(array(numeric_inputs).alias(\"mins\")) # Create an array for all mins and select only the input cols\n",
    "    df_minimum = min_array.select(array_min(min_array.mins)).collect() # Collect golobal min as Python object\n",
    "    df_minimum = df_minimum[0][0] # Slice to get the number itself\n",
    "\n",
    "    features_list = numeric_inputs + string_inputs\n",
    "    assembler = VectorAssembler(inputCols=features_list,outputCol='features')\n",
    "    output = assembler.transform(indexed).select('features','label')\n",
    "\n",
    "#     final_data = output.select('features','label') #drop everything else\n",
    "    \n",
    "    # Now check for negative values and ask user if they want to correct that? \n",
    "    if df_minimum < 0:\n",
    "        print(\" \")\n",
    "        print(\"WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contains negative values\")\n",
    "        print(\" \")\n",
    "    \n",
    "    if treat_neg_values == True:\n",
    "        print(\"You have opted to correct that by rescaling all your features to a range of 0 to 1\")\n",
    "        print(\" \")\n",
    "        print(\"We are rescaling you dataframe....\")\n",
    "        scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "        # Compute summary statistics and generate MinMaxScalerModel\n",
    "        scalerModel = scaler.fit(output)\n",
    "\n",
    "        # rescale each feature to range [min, max].\n",
    "        scaled_data = scalerModel.transform(output)\n",
    "        final_data = scaled_data.select('label','scaledFeatures')\n",
    "        final_data = final_data.withColumnRenamed('scaledFeatures','features')\n",
    "        print(\"Done!\")\n",
    "\n",
    "    else:\n",
    "        print(\"You have opted not to correct that therefore you will not be able to use to Naive Bayes classifier\")\n",
    "        print(\"We will return the dataframe unscaled.\")\n",
    "        final_data = output\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Test run!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are correcting for non normality now!\n",
      "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
      " \n",
      "We are rescaling you dataframe....\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0    1.0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...\n",
       "1    0.0  (1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...\n",
       "2    0.0  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...\n",
       "3    0.0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "4    0.0  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ..."
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "col_list = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"Age_Mons\",\"Qchat-10-Score\",\"Sex\",\"Ethnicity\",\"Jaundice\",\"Family_mem_with_ASD\",\"Who completed the test\"]\n",
    "\n",
    "input_columns = col_list\n",
    "dependent_var = 'Class/ASD Traits '\n",
    "\n",
    "final_data = MLClassifierDFPrep(df,input_columns,dependent_var)\n",
    "final_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Testing and evaluating function</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassTrainEval(classifier,features,classes,train,test):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "    \n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
    "        \n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # instantiate the base classifier.\n",
    "            lr = LogisticRegression()\n",
    "            # instantiate the One Vs Rest Classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "#             fitModel = OVRclassifier.fit(train)\n",
    "            # Add parameters of your choice here:\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "                .build()\n",
    "            #Cross Validator requires the following parameters:\n",
    "            crossval = CrossValidator(estimator=OVRclassifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 is best practice\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # specify layers for the neural network:\n",
    "            # input layer of size features, two intermediate of features+1 and same size as features\n",
    "            # and output of size number of classes\n",
    "            # Note: crossvalidator cannot be used here\n",
    "            features_count = len(features[0][0])\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: # These classifiers currently only accept binary classification\n",
    "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "            return\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "  \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LogisticRegression\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"NaiveBayes\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LinearSVC\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .build())\n",
    "            \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .build())\n",
    "            \n",
    "            #Cross Validator requires all of the following parameters:\n",
    "            crossval = CrossValidator(estimator=classifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 + is best practice\n",
    "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
    "    \n",
    "    # Print feature selection metrics\n",
    "    if fitModel is not None:\n",
    "        \n",
    "        if Mtype in(\"OneVsRest\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            # Extract list of binary models\n",
    "            models = BestModel.models\n",
    "            for model in models:\n",
    "                print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            print(\"\")\n",
    "            print('\\033[1m' + Mtype,\" Weights\"+ '\\033[0m')\n",
    "            print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "            print(\"\")\n",
    "\n",
    "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\n",
    "            # FEATURE IMPORTANCES\n",
    "            # Estimate of the importance of each feature.\n",
    "            # Each featureâ€™s importance is the average of its importance across all trees \n",
    "            # in the ensemble The importance vector is normalized to sum to 1. \n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Feature Importances\"+ '\\033[0m')\n",
    "            print(\"(Scores add up to 1)\")\n",
    "            print(\"Lowest score is the least important\")\n",
    "            print(\" \")\n",
    "            featureImportances = BestModel.featureImportances.toArray()\n",
    "            print(featureImportances)\n",
    "            \n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                global DT_featureImportances\n",
    "                DT_featureImportances = BestModel.featureImportances.toArray()\n",
    "                global DT_BestModel\n",
    "                DT_BestModel = BestModel\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                global GBT_featureImportances\n",
    "                GBT_featureImportances = BestModel.featureImportances.toArray()\n",
    "                global GBT_BestModel\n",
    "                GBT_BestModel = BestModel\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                global RF_featureImportances\n",
    "                RF_featureImportances = BestModel.featureImportances.toArray()\n",
    "                global RF_BestModel\n",
    "                RF_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LogisticRegression\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficient Matrix\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "            print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "            global LR_coefficients\n",
    "            LR_coefficients = BestModel.coefficientMatrix.toArray()\n",
    "            global LR_BestModel\n",
    "            LR_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LinearSVC\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficients\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "            global LSVC_coefficients\n",
    "            LSVC_coefficients = BestModel.coefficients.toArray()\n",
    "            global LSVC_BestModel\n",
    "            LSVC_BestModel = BestModel\n",
    "        \n",
    "   \n",
    "    # Set the column names to match the external results dataframe that we will join with later:\n",
    "    columns = ['Classifier', 'Result']\n",
    "    \n",
    "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
    "        Mtype = [Mtype] # make this a list\n",
    "        score = [\"N/A\"]\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    else:\n",
    "        predictions = fitModel.transform(test)\n",
    "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
    "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "        Mtype = [Mtype] # make this a string\n",
    "        score = [str(accuracy)] #make this a string and convert to a list\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "        \n",
    "    return result\n",
    "    #Also returns the fit model important scores or p values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Too long for me I guess? Better to split it a little bit. Also probably very time consuming. But still a good source.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Test Run!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[ -5.74826963,  -5.88605442,  -5.7136875 ,  -5.64906936,\n",
      "               -5.49625639,  -5.86266633,  -6.33965982,  -5.49307227,\n",
      "               -6.38637691,  -5.93037897,   0.03782589, -16.69952918,\n",
      "                0.18956656,  -0.75559565,  -0.51833962,  -0.19425441,\n",
      "               -9.58377893]])\n",
      "Intercept: [26.888162137531307]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -7.435940405560727 \u001b[1m\n",
      "Coefficients:\u001b[0m [1.5426091771792398,1.8014770692007012,1.2906738274071288,1.5146930541860517,1.4805674045093462,1.6484001984963874,1.6509116447967473,1.5165470502758096,2.0817681499674063,1.483337728646401,0.2930327345686611,4.575638620467662,-0.17176988123414272,0.5507928698449102,0.44382006219496994,-0.15660900773580122,1.744358219859474]\n",
      "\u001b[1mIntercept: \u001b[0m 7.43594040556073 \u001b[1m\n",
      "Coefficients:\u001b[0m [-1.5426091771792385,-1.8014770692007032,-1.2906738274071308,-1.5146930541860524,-1.4805674045093447,-1.6484001984963899,-1.650911644796748,-1.516547050275809,-2.081768149967407,-1.483337728646401,-0.2930327345686658,-4.57563862046766,0.17176988123414347,-0.5507928698449125,-0.4438200621949675,0.15660900773580155,-1.7443582198594718]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.4207909889464757,-0.7911376226431002,-0.18659630959529414,-0.3756676751889045,-0.5225014758042397,-0.5471752322708483,-0.5220623019804348,-0.6154517326459293,-0.868370072927947,-0.19183900381790797,0.5837177989260944,-1.4145494890613346,0.056933014448060926,-0.0,-0.0,0.33083311388572334,-0.6462652216674974]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "[0.04251638 0.00945794 0.         0.014062   0.04677675 0.11215447\n",
      " 0.2462996  0.         0.12561506 0.00996292 0.         0.39315487\n",
      " 0.         0.         0.         0.         0.        ]\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "[0.00000000e+00 0.00000000e+00 9.50128304e-19 3.68174718e-18\n",
      " 9.18457361e-17 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.18766038e-18 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 3.91927926e-18 0.00000000e+00 0.00000000e+00\n",
      " 4.21445245e-15]\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 683\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |100.0 |\n",
      "|OneVsRest                     |100.0 |\n",
      "|LinearSVC                     |97.48 |\n",
      "|NaiveBayes                    |84.59 |\n",
      "|RandomForestClassifier        |100.0 |\n",
      "|GBTClassifier                 |100.0 |\n",
      "|DecisionTreeClassifier        |100.0 |\n",
      "|MultilayerPerceptronClassifier|100.0 |\n",
      "+------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This part is just okay, basic testing\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql import functions\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Comment out Naive Bayes if your data still contains negative values\n",
    "classifiers = [\n",
    "                LogisticRegression()\n",
    "                ,OneVsRest()\n",
    "               ,LinearSVC()\n",
    "               ,NaiveBayes()\n",
    "               ,RandomForestClassifier()\n",
    "               ,GBTClassifier()\n",
    "               ,DecisionTreeClassifier()\n",
    "               ,MultilayerPerceptronClassifier()\n",
    "              ] \n",
    "\n",
    "train,test = final_data.randomSplit([0.7,0.3])\n",
    "features = final_data.select(['features']).collect()\n",
    "# Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "class_count = final_data.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "\n",
    "#set up your results table\n",
    "columns = ['Classifier', 'Result']\n",
    "vals = [(\"Place Holder\",\"N/A\")]\n",
    "results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    new_result = ClassTrainEval(classifier,features,classes,train,test)\n",
    "    results = results.union(new_result)\n",
    "results = results.where(\"Classifier!='Place Holder'\")\n",
    "results.show(100,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Diagnostics</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It is info about our testing but in more depth. It could be useful in future.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.classification import *\n",
    "\n",
    "def ClassDiag(classifier):\n",
    "    \n",
    "    # Fit our model\n",
    "    C = classifier\n",
    "    fitModel = C.fit(train)\n",
    "\n",
    "    # Load the Summary\n",
    "    trainingSummary = fitModel.summary\n",
    "\n",
    "    # General Describe\n",
    "    trainingSummary.predictions.describe().show()\n",
    "\n",
    "    # View Predictions\n",
    "    pred_and_labels = fitModel.evaluate(test)\n",
    "    pred_and_labels.predictions.show()\n",
    "\n",
    "    # Print the coefficients and intercept for multinomial logistic regression\n",
    "    print(\"Coefficients: \\n\" + str(fitModel.coefficientMatrix))\n",
    "    print(\" \")\n",
    "    print(\"Intercept: \" + str(fitModel.interceptVector))\n",
    "    print(\" \")\n",
    "\n",
    "    # Obtain the objective per iteration\n",
    "    objectiveHistory = trainingSummary.objectiveHistory\n",
    "    print(\" \")\n",
    "    print(\"objectiveHistory:\")\n",
    "    for objective in objectiveHistory:\n",
    "        print(objective)\n",
    "\n",
    "    # for multiclass, we can inspect metrics on a per-label basis\n",
    "    print(\" \")\n",
    "    print(\"False positive rate by label:\")\n",
    "    for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "        print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"True positive rate by label:\")\n",
    "    for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "        print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Precision by label:\")\n",
    "    for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "        print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Recall by label:\")\n",
    "    for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "        print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"F-measure by label:\")\n",
    "    for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "        print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "    accuracy = trainingSummary.accuracy\n",
    "    falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "    truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "    fMeasure = trainingSummary.weightedFMeasure()\n",
    "    precision = trainingSummary.weightedPrecision\n",
    "    recall = trainingSummary.weightedRecall\n",
    "    print(\" \")\n",
    "    print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "          % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              label|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                736|                736|\n",
      "|   mean|             0.3125|             0.3125|\n",
      "| stddev|0.46382761282805135|0.46382761282805135|\n",
      "|    min|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(17,[0,1,2,3,4,5,...|[192.286546049392...|[1.0,3.0975199095...|       0.0|\n",
      "|  0.0|(17,[0,1,2,3,4,5,...|[157.706929220363...|[1.0,3.2266427365...|       0.0|\n",
      "|  0.0|(17,[0,1,2,3,4,5,...|[158.310679045804...|[1.0,1.7641912512...|       0.0|\n",
      "|  0.0|(17,[0,1,2,3,4,6,...|[157.628655938967...|[1.0,3.4893500180...|       0.0|\n",
      "|  0.0|(17,[0,1,2,3,4,6,...|[123.421917855621...|[1.0,2.5034684893...|       0.0|\n",
      "|  0.0|(17,[0,1,2,3,6,7,...|[122.853303343796...|[1.0,4.4206718105...|       0.0|\n",
      "|  0.0|(17,[0,1,2,3,6,8,...|[88.4695360407011...|[1.0,3.7858960124...|       0.0|\n",
      "|  0.0|(17,[0,1,2,4,6,7,...|[120.766340411787...|[1.0,3.5632374115...|       0.0|\n",
      "|  0.0|(17,[0,1,3,4,5,6,...|[160.428148946998...|[1.0,2.1229519779...|       0.0|\n",
      "|  0.0|(17,[0,1,3,4,5,6,...|[160.428148946998...|[1.0,2.1229519779...|       0.0|\n",
      "|  0.0|(17,[0,1,3,4,5,6,...|[124.266219235347...|[1.0,1.0761348577...|       0.0|\n",
      "|  0.0|(17,[0,1,3,4,5,6,...|[88.1431921105233...|[1.0,5.2468427578...|       0.0|\n",
      "|  0.0|(17,[0,1,3,4,5,7,...|[122.399361762526...|[1.0,6.9603743523...|       0.0|\n",
      "|  0.0|(17,[0,1,3,4,6,8,...|[124.335174063039...|[1.0,1.0044307454...|       0.0|\n",
      "|  0.0|(17,[0,1,3,5,6,7,...|[87.0681371244456...|[1.0,1.5374057366...|       0.0|\n",
      "|  0.0|(17,[0,1,3,6,7,8,...|[123.319756664881...|[1.0,2.7727465321...|       0.0|\n",
      "|  0.0|(17,[0,1,3,7,9,10...|[52.3732983723186...|[1.0,1.7970721667...|       0.0|\n",
      "|  0.0|(17,[0,1,4,5,6,7,...|[123.202978829827...|[1.0,3.1162058617...|       0.0|\n",
      "|  0.0|(17,[0,1,4,5,6,8,...|[123.838464251985...|[1.0,1.6505866492...|       0.0|\n",
      "|  0.0|(17,[0,1,4,5,6,9,...|[88.2132728316098...|[1.0,4.8917288798...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Coefficients: \n",
      "DenseMatrix([[-2.82162952e+01, -2.66376465e+01, -2.65591424e+01,\n",
      "              -2.81690018e+01, -2.68541976e+01, -2.79328082e+01,\n",
      "              -2.84358806e+01, -2.68149474e+01, -2.84976996e+01,\n",
      "              -2.79683352e+01, -1.43130211e+00, -7.88394461e+01,\n",
      "              -5.47482679e-03, -2.19714470e+00, -9.79722426e-01,\n",
      "              -8.73456111e-01, -8.18738389e+00]])\n",
      " \n",
      "Intercept: [126.78657453814166]\n",
      " \n",
      " \n",
      "objectiveHistory:\n",
      "0.621086374555251\n",
      "0.515359652015492\n",
      "0.4510918159776202\n",
      "0.2816368327650025\n",
      "0.25514853314801395\n",
      "0.21652220322509297\n",
      "0.195906403955139\n",
      "0.17240023040630587\n",
      "0.13563648071053738\n",
      "0.07782172868756751\n",
      "0.04256784966101516\n",
      "0.02451945651077245\n",
      "0.015928170700917434\n",
      "0.009572084788632846\n",
      "0.008617810218142306\n",
      "0.0046681365462539525\n",
      "0.0026897572007411534\n",
      "0.0013903369986535477\n",
      "0.0007089471850782447\n",
      "0.0003537259101921082\n",
      "0.00017661367928608048\n",
      "8.888102147942092e-05\n",
      "4.200849889973237e-05\n",
      "2.105681805270629e-05\n",
      "1.0489560956430425e-05\n",
      "5.265264377206957e-06\n",
      "4.19066851119447e-06\n",
      "1.2844421644849105e-06\n",
      "8.168540235952549e-07\n",
      "3.8210070056234534e-07\n",
      "2.0024443398209787e-07\n",
      "1.0003871916145816e-07\n",
      "5.0790358129865525e-08\n",
      "2.557633106050406e-08\n",
      "1.2899499046158573e-08\n",
      "6.492324578504009e-09\n",
      " \n",
      "False positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      " \n",
      "True positive rate by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "Precision by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "Accuracy: 1.0\n",
      "FPR: 0.0\n",
      "TPR: 1.0\n",
      "F-measure: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "ClassDiag(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The End***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
